{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-Based Decision Making\n",
    "\n",
    "This notebook contains the final code of Group 22's assignment for the course EPA1361.\n",
    "\n",
    "In this code, we explore scenarios for the studied policy problem (flood risk management for the IJssel river) using open exploration, and then apply directed search (MORDM) to find optimal results.\n",
    "\n",
    "## Table of contents\n",
    "1. [Exploration](#Exploration)\n",
    "    1. [Problem formulation 3](#Problem-formulation-3)\n",
    "    2. [Problem formulation 4](#Problem-formulation-4)\n",
    "2. [Optimization](#Optimization)\n",
    "    1. [Convergence](#Convergence)\n",
    "    2. [Constraints and solutions](#Constraints-and-solutions)\n",
    "    3. [Uncertainty](#Uncertainty)\n",
    "    4. [Scenario discovery using PRIM](#Scenario-discovery-using-PRIM)\n",
    "    5. [Sensitivity analysis using extra trees](#Sensitivity-analysis-using-extra-trees)\n",
    "    6. [Robustness](#Robustness)\n",
    "\n",
    "_The items in this table of contents may only be clickable in the browser version of Jupyter Notebook._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:11:54.569169Z",
     "end_time": "2023-06-20T18:11:54.571108Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "save_exploration_data = False\n",
    "save_figures = True\n",
    "save_hv_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:11:54.572210Z",
     "end_time": "2023-06-20T18:11:55.346544Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# All needed imports\n",
    "## Standard packages\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import collections\n",
    "## EMA workbench!\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    Scenario,\n",
    "    MultiprocessingEvaluator,\n",
    "    HypervolumeMetric,\n",
    "    ScalarOutcome,\n",
    "    ema_logging,\n",
    "    save_results\n",
    ")\n",
    "## EMA workbench - optimization\n",
    "from ema_workbench.em_framework.optimization import (ArchiveLogger, EpsilonProgress, to_problem)\n",
    "## EMA workbench - analysis\n",
    "from ema_workbench.analysis import (\n",
    "    parcoords,\n",
    "    prim,\n",
    "    dimensional_stacking,\n",
    "    feature_scoring,\n",
    "    scenario_discovery_util\n",
    ")\n",
    "## IJssel dike model\n",
    "from problem_formulation import get_model_for_problem_formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:11:55.348604Z",
     "end_time": "2023-06-20T18:11:55.350147Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Set up\n",
    "## Set up logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "## Set up folders\n",
    "if save_exploration_data:\n",
    "    exploration_data_path = \"./MBDM_Final_Data/Exploration_Data\"\n",
    "    Path(exploration_data_path).mkdir(parents=True, exist_ok=True)\n",
    "if save_figures:\n",
    "    figures_path = \"./MBDM_Final_Data/Figures\"\n",
    "    Path(figures_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "We will explore five policies:\n",
    "\n",
    "1. a baseline (no actions taken)\n",
    "2. implementing room for the river (RfR) everywhere\n",
    "3. heightening all dikes by 50cm in every timestep\n",
    "4. RfR only near Natura 2000 areas (dike rings 1 and 2), dike heightening of 50 cm in timestep 3 in the other dike rings\n",
    "5. the final policy of the MBDM debate, including RfR in dike rings 1 and 4, and moderate dike heightening in each dike ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:11:55.353187Z",
     "end_time": "2023-06-20T18:11:55.355349Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# In the two problem formulations we want to explore, the levers are the same.\n",
    "# This function will return the policy list, based on the default values of a problem formulation.\n",
    "\n",
    "def get_policies(do_nothing_dict):\n",
    "    return [\n",
    "        Policy(\"Baseline\", **do_nothing_dict),\n",
    "        Policy(\"RfR everywhere\",\n",
    "            **dict(\n",
    "                do_nothing_dict,\n",
    "                **{'0_RfR 0':1,\n",
    "                    '0_RfR 1':1,\n",
    "                    '0_RfR 2':1,\n",
    "                    '1_RfR 0':1,\n",
    "                    '1_RfR 1':1,\n",
    "                    '1_RfR 2':1,\n",
    "                    '2_RfR 0':1,\n",
    "                    '2_RfR 1':1,\n",
    "                    '2_RfR 2':1,\n",
    "                    '3_RfR 0':1,\n",
    "                    '3_RfR 1':1,\n",
    "                    '3_RfR 2':1,\n",
    "                    '4_RfR 0':1,\n",
    "                    '4_RfR 1':1,\n",
    "                    '4_RfR 2':1\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "        Policy(\"Dike heightening everywhere\",\n",
    "            **dict(\n",
    "                do_nothing_dict,\n",
    "                **{'A.1_DikeIncrease 0':5,\n",
    "                    'A.1_DikeIncrease 1':5,\n",
    "                    'A.1_DikeIncrease 2':5,\n",
    "                    'A.2_DikeIncrease 0':5,\n",
    "                    'A.2_DikeIncrease 1':5,\n",
    "                    'A.2_DikeIncrease 2':5,\n",
    "                    'A.3_DikeIncrease 0':5,\n",
    "                    'A.3_DikeIncrease 1':5,\n",
    "                    'A.3_DikeIncrease 2':5,\n",
    "                    'A.4_DikeIncrease 0':5,\n",
    "                    'A.4_DikeIncrease 1':5,\n",
    "                    'A.4_DikeIncrease 2':5,\n",
    "                    'A.5_DikeIncrease 0':5,\n",
    "                    'A.5_DikeIncrease 1':5,\n",
    "                    'A.5_DikeIncrease 2':5\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "        # Dike heightening occurs only in the last timesteps.\n",
    "        Policy(\"RfR in Natura 2000 areas\",\n",
    "            **dict(\n",
    "                do_nothing_dict,\n",
    "                **{'0_RfR 0':1,\n",
    "                   '1_RfR 0':1,\n",
    "                   'A.3_DikeIncrease 0': 0,\n",
    "                   'A.3_DikeIncrease 1': 0,\n",
    "                   'A.3_DikeIncrease 2': 5,\n",
    "                   'A.4_DikeIncrease 0': 0,\n",
    "                   'A.4_DikeIncrease 1': 0,\n",
    "                   'A.4_DikeIncrease 2': 5,\n",
    "                   'A.5_DikeIncrease 0': 0,\n",
    "                   'A.5_DikeIncrease 1': 0,\n",
    "                   'A.5_DikeIncrease 2': 5\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "        # Policy agreed upon by majority of actors during the debate\n",
    "        Policy(\"Final approved policy\",\n",
    "            **dict(\n",
    "                do_nothing_dict,\n",
    "                **{'0_RfR 0': 1,\n",
    "                   'A.1_DikeIncrease 1': 3,\n",
    "                   'A.2_DikeIncrease 0': 3,\n",
    "                   'A.3_DikeIncrease 0': 10,\n",
    "                   '3_RfR 0': 1,\n",
    "                   'A.4_DikeIncrease 1': 3,\n",
    "                   'A.5_DikeIncrease 0': 10\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "# The code for the two studied problem formulations could also be simplfied into a loop, but it is convenient to keep them separate if steps or parameters need to be changed for one of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem formulation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:11:55.355631Z",
     "end_time": "2023-06-20T18:11:55.466003Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Get the model\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "## Function to get default values for all levers\n",
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:11:55.466820Z",
     "end_time": "2023-06-20T18:11:55.468155Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Define policies to explore\n",
    "policies = get_policies(get_do_nothing_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:11:55.469307Z",
     "end_time": "2023-06-20T18:12:22.354785Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Run the model with the EMA workbench\n",
    "n_scenarios = 200\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:22.355285Z",
     "end_time": "2023-06-20T18:12:22.356968Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save exploration results if needed\n",
    "if save_exploration_data:\n",
    "    save_results(results, exploration_data_path + '/exploration_PF3_results.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:22.357368Z",
     "end_time": "2023-06-20T18:12:22.359299Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate results into experiments and outcomes, and select policies\n",
    "experiments, outcomes = results\n",
    "policies = experiments['policy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:22.360118Z",
     "end_time": "2023-06-20T18:12:22.361921Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert outcomes into a dataframe to plot\n",
    "data = pd.DataFrame.from_dict(outcomes)\n",
    "data['policy'] = policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:22.363617Z",
     "end_time": "2023-06-20T18:12:25.314759Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plot = sns.pairplot(data, hue='policy', vars=outcomes.keys(), )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    plot.figure.savefig(figures_path + \"/exploration_PF3_policies.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:25.331157Z",
     "end_time": "2023-06-20T18:12:26.815079Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem formulation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:26.815868Z",
     "end_time": "2023-06-20T18:12:26.878667Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Get the model\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(3)\n",
    "\n",
    "## Function to get default values for all levers\n",
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:26.879208Z",
     "end_time": "2023-06-20T18:12:26.880698Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Define policies to explore\n",
    "policies = get_policies(get_do_nothing_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:26.945975Z",
     "end_time": "2023-06-20T18:12:53.172157Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Run the model with the EMA workbench\n",
    "n_scenarios = 200\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:53.172933Z",
     "end_time": "2023-06-20T18:12:53.174498Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save exploration results if needed\n",
    "if save_exploration_data:\n",
    "    save_results(results, exploration_data_path + '/exploration_PF4_results.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:53.175647Z",
     "end_time": "2023-06-20T18:12:53.176670Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Separate results into experiments and outcomes, and select policies\n",
    "experiments, outcomes = results\n",
    "policies = experiments['policy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:53.177770Z",
     "end_time": "2023-06-20T18:12:53.179192Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert outcomes into a dataframe to plot\n",
    "data = pd.DataFrame.from_dict(outcomes)\n",
    "data['policy'] = policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T18:12:53.180432Z",
     "end_time": "2023-06-20T18:13:10.308174Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plot = sns.pairplot(data, hue='policy', vars=outcomes.keys(), )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    plot.figure.savefig(figures_path + \"/exploration_PF4_policies.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:52:04.121467Z",
     "end_time": "2023-06-20T17:52:04.123757Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Optimization settings\n",
    "convergence_metrics = [EpsilonProgress()]\n",
    "nfe = 1000\n",
    "epsilon = [0.5,0.5,0.5,0.01,0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Each epsilon value corresponds to a model outcome.\n",
    "The model outcomes are: expected damages, dike investment costs, rfr costs, evacuation cost, and casualties.\n",
    "We select higher epsilon values to damages and costs, while we choose lower values for evacuation costs and casualties._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:52:04.124190Z",
     "end_time": "2023-06-20T17:52:04.191846Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Get the model\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)\n",
    "\n",
    "# The model requires a reference scenario to \"kick-start\"\n",
    "reference_scenario = Scenario('reference', **{\n",
    "    'discount rate 0': 1.5,\n",
    "    'discount rate 1': 1.5,\n",
    "    'discount rate 2': 1.5,\n",
    "    'A.0_ID flood wave shape': 75,\n",
    "    'A.1_Bmax': 240,\n",
    "    'A.1_pfail': 0.25,\n",
    "    'A.1_Brate': 10,\n",
    "    'A.2_Bmax': 240,\n",
    "    'A.2_pfail': 0.25,\n",
    "    'A.2_Brate': 10,\n",
    "    'A.3_Bmax': 240,\n",
    "    'A.3_pfail': 0.25,\n",
    "    'A.3_Brate': 10,\n",
    "    'A.4_Bmax': 240,\n",
    "    'A.4_pfail': 0.25,\n",
    "    'A.4_Brate': 10,\n",
    "    'A.5_Bmax': 240,\n",
    "    'A.5_pfail': 0.25,\n",
    "    'A.5_Brate': 10\n",
    "})\n",
    "\n",
    "# Set up data folder and remove \"tmp\" folder if left from previous runs\n",
    "optimization_data_path = \"./MBDM_Final_Data/Optimization_Data\"\n",
    "Path(optimization_data_path).mkdir(parents=True, exist_ok=True)\n",
    "tmppath = Path(optimization_data_path) / 'tmp'\n",
    "if tmppath.exists() and tmppath.is_dir():\n",
    "    shutil.rmtree(tmppath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:52:04.192785Z",
     "end_time": "2023-06-20T17:52:04.195443Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Set convergence metrics\n",
    "mordm_data_filename = \"MORDM_HV_1.tar.gz\"\n",
    "convergence_metrics = [\n",
    "    # Save data as archive, for hypervolume\n",
    "    ArchiveLogger(\n",
    "        optimization_data_path,\n",
    "        [l.name for l in dike_model.levers],\n",
    "        [o.name for o in dike_model.outcomes],\n",
    "        base_filename=mordm_data_filename,\n",
    "    ),\n",
    "    # Track epsilon progress\n",
    "    EpsilonProgress(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:52:04.195896Z",
     "end_time": "2023-06-20T17:52:33.967794Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    optimization_result, optimization_convergence = evaluator.optimize(nfe=nfe, searchover='levers', epsilons=epsilon, convergence=convergence_metrics,reference=reference_scenario)\n",
    "\n",
    "optimization_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence\n",
    "\n",
    "Hypervolume is very resource-intensive to run. Its convergence can be clearly seen above 10000 function evaluations, and so we do not run hypervolume if the chosen nfe is above a certain limit."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sanitize data\n",
    "Here, there is an issue between the dike model and the EMA Workbench. The dike model defines value keys (levers, uncertainties, outcomes) that do not follow Python identifier standards, by including spaces or dots, or starting with digits.\n",
    "\n",
    "We avoid this by replacing disallowed symbols with allowed (but otherwise unused) symbols, Ç and Ñ. We also add the letter \"A\" in front of keys starting with digits."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimization_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcopy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deepcopy\n\u001B[0;32m----> 3\u001B[0m result_sanitized \u001B[38;5;241m=\u001B[39m \u001B[43moptimization_result\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m      4\u001B[0m model_sanitized \u001B[38;5;241m=\u001B[39m deepcopy(dike_model)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Here, we need to rename...\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'optimization_result' is not defined"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "result_sanitized = optimization_result.copy()\n",
    "model_sanitized = deepcopy(dike_model)\n",
    "\n",
    "# Here, we need to rename...\n",
    "def sanitize_as_python_identifier(x):\n",
    "    # Replace dots\n",
    "    x = x.replace(\".\",\"Ç\")\n",
    "    # Replace spaces\n",
    "    x = x.replace(\" \",\"Ñ\")\n",
    "    # Add letter if starts with digit\n",
    "    if x.startswith((\"0\",\"1\",\"2\",\"3\",\"4\",\"5\")):\n",
    "        x = \"A\" + x\n",
    "    return x\n",
    "\n",
    "# Reverse functions for if we need to get the original labels...\n",
    "def desanitize_as_python_identifier(x):\n",
    "    # Replace dots\n",
    "    x = x.replace(\"Ç\",\".\")\n",
    "    # Replace spaces\n",
    "    x = x.replace(\"Ñ\",\" \")\n",
    "    # Add letter if starts with digit\n",
    "    if x.startswith((\"A0\",\"A1\",\"A2\",\"A3\",\"A4\",\"A5\")):\n",
    "        x = x[1:]\n",
    "    return x\n",
    "\n",
    "result_sanitized.columns = [sanitize_as_python_identifier(x) for x in result_sanitized.columns]\n",
    "\n",
    "for lev in model_sanitized.levers:\n",
    "    lev.name = sanitize_as_python_identifier(lev.name)\n",
    "\n",
    "for unc in model_sanitized.uncertainties:\n",
    "    unc.name = sanitize_as_python_identifier(unc.name)\n",
    "\n",
    "for out in model_sanitized.outcomes:\n",
    "    out.name = sanitize_as_python_identifier(out.name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypervolume\n",
    "hv_max_nfe = 14000\n",
    "if nfe <= hv_max_nfe:\n",
    "    # Load data from archive\n",
    "    archives = ArchiveLogger.load_archives(optimization_data_path + \"/\" + mordm_data_filename)\n",
    "\n",
    "    problem = to_problem(model_sanitized, searchover=\"levers\")\n",
    "\n",
    "    hv = HypervolumeMetric(result_sanitized, problem)\n",
    "\n",
    "    print(f\"Going over {len(archives.items())} archives...\")\n",
    "    hypervolume = []\n",
    "\n",
    "    # As this is a very slow process, we want to store the results at every step if something goes wrong\n",
    "    if save_hv_data:\n",
    "        hypervolume_folder = optimization_data_path + f\"/Hypervolume_Data/hv_{str(round(datetime.now().timestamp()))}\"\n",
    "        Path(hypervolume_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i, (nfe, archive) in enumerate(archives.items()):\n",
    "        print(datetime.now().strftime('%H:%M:%S') + \" - Hypervolume calculate for archive #\" + str(i))\n",
    "        archive_sanitized = archive\n",
    "        #archive_sanitized.columns = [sanitize_as_python_identifier(x) for x in archive_sanitized.columns]\n",
    "        the_result = (nfe, hv.calculate(archive))\n",
    "        hypervolume.append(the_result)\n",
    "        if save_hv_data:\n",
    "            filename = hypervolume_folder + \"/\" + f\"hv_data_count_{i}.json\"\n",
    "            with open(filename, \"w\") as fp:\n",
    "                json.dump(hypervolume, fp)\n",
    "            print(datetime.now().strftime('%H:%M:%S') + \" - Dumped hv data into file \" + filename)\n",
    "        # may be read with open(\"test\", \"r\") - not implemented\n",
    "\n",
    "    hypervolume.sort(key=lambda x:x[0])\n",
    "    hypervolume = np.asarray(hypervolume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot convergence metrics\n",
    "if nfe <= hv_max_nfe:\n",
    "    # Plot both\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, figsize=(8,4))\n",
    "    ax1.plot(optimization_convergence.nfe, optimization_convergence.epsilon_progress)\n",
    "    ax1.set_ylabel('$\\epsilon$ progress')\n",
    "    ax2.plot(hypervolume[:, 0], hypervolume[:, 1])\n",
    "    ax2.set_ylim(ymin=0)\n",
    "    ax2.set_ylabel('hypervolume progress')\n",
    "    ax1.set_xlabel('number of function evaluations')\n",
    "    ax2.set_xlabel('number of function evaluations')\n",
    "    plt.show()\n",
    "    if save_figures:\n",
    "        plt.savefig(figures_path + f\"/mordm_convergence_{nfe}.png\", dpi=300)\n",
    "else:\n",
    "    # Plot only epsilon\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(optimization_convergence.nfe, optimization_convergence.epsilon_progress)\n",
    "    ax.set_ylabel('$\\epsilon$ progress')\n",
    "    ax.set_xlabel('number of function evaluations')\n",
    "    plt.show()\n",
    "    if save_figures:\n",
    "        plt.savefig(figures_path + f\"/mordm_convergence_{nfe}.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints and solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot initial pool of solutions\n",
    "outcome_data = optimization_result.loc[:, [o.name for o in dike_model.outcomes]]\n",
    "outcome_limits = parcoords.get_limits(outcome_data)\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(outcome_limits)\n",
    "paraxes.plot(outcome_data)\n",
    "plt.title(\"All scenarios\")\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    paraxes.fig.savefig(figures_path + f\"/parcoords_outcomes_{nfe}.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These found solutions will now be constrained to the most for the Delta Commission. For a solution to be allowable, the following criteria must be met:\n",
    "\n",
    "* Expected number of deaths should not exceed **0.001**.\n",
    "* **Adaptability**: follow real-life common sense in the long run. Concretely, **not executing RfR in a location where dikes have been previously heightened**, thus undoing the initial investment. The other way around is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain solutions by # of deaths\n",
    "optimization_result_constrained = optimization_result[optimization_result['Expected Number of Deaths'] < 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain solutions by excluding dike heightening -> RfR scenarios\n",
    "def has_rfr_after_dh(series):\n",
    "    for area in range(5):\n",
    "        first_rfr_timestep = -1\n",
    "        for timestep in range(3):\n",
    "            if series[f\"{area}_RfR {timestep}\"] > 0:\n",
    "                first_rfr_timestep = timestep\n",
    "                break\n",
    "        last_dike_timestep = 3\n",
    "        for timestep in range(3):\n",
    "            if series[f\"A.{area + 1}_DikeIncrease {timestep}\"] > 0:\n",
    "                last_dike_timestep = timestep\n",
    "        if first_rfr_timestep > last_dike_timestep:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "optimization_result_constrained = optimization_result_constrained[optimization_result_constrained.apply(has_rfr_after_dh, axis=\"columns\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns for outcomes from the dataframe, resulting in a df of polcies\n",
    "## Quan: do we need this?\n",
    "optimization_policies = optimization_result_constrained.drop([o.name for o in dike_model.outcomes], axis=1)\n",
    "optimization_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO**: We should say something about the trade-offs that we found on the small set of solutions. For instance, sacrificing costs for lower deaths or costs for RfR as a measure of adaptability...\n",
    "I think here would be very interesting to say something about the model and the constraints it was of the evaluation of RfR. Only one type (although there are many), and checking the water level only in winter (which is a good thing for the transport company to have RfR because when there are droughts they cannot pass anyways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the constrained pool of solutions\n",
    "outcome_data_constrained = optimization_result_constrained.loc[:, [o.name for o in dike_model.outcomes]]\n",
    "outcome_limits_constrained = parcoords.get_limits(outcome_data_constrained)\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(outcome_limits_constrained)\n",
    "plot = paraxes.plot(outcome_data_constrained)\n",
    "plt.title(\"Constrained scenarios\")\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    plot.figure.savefig(figures_path + f\"/parcoords_outcomes_{nfe}_constrained.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty\n",
    "\n",
    "Re-evaluate candidate solutions under uncertainty. Performing experiments with 1000 scenarios for each of the policy options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build list of policies\n",
    "policies_to_evaluate = []\n",
    "\n",
    "for i, policy in optimization_policies.iterrows():\n",
    "    policies_to_evaluate.append(Policy(str(i), **policy.to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:56:13.054128Z",
     "end_time": "2023-06-20T17:57:36.685665Z"
    }
   },
   "outputs": [],
   "source": [
    "n_scenarios = 1000 # the amount of scenarios for each policy option\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(n_scenarios, policies_to_evaluate)\n",
    "\n",
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:57:36.686004Z",
     "end_time": "2023-06-20T17:57:36.689017Z"
    }
   },
   "outputs": [],
   "source": [
    "outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario discovery using PRIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:57:36.689639Z",
     "end_time": "2023-06-20T17:57:36.693741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean up data = policy parameters, only leaving outcomes etc.\n",
    "columns_to_drop = ['A.1_DikeIncrease 0','A.1_DikeIncrease 1','A.1_DikeIncrease 2','A.2_DikeIncrease 0','A.2_DikeIncrease 1','A.2_DikeIncrease 2','A.3_DikeIncrease 0','A.3_DikeIncrease 1','A.3_DikeIncrease 2','A.4_DikeIncrease 0','A.4_DikeIncrease 1','A.4_DikeIncrease 2','A.5_DikeIncrease 0','A.5_DikeIncrease 1','A.5_DikeIncrease 2', 'policy']\n",
    "columns_to_drop += ['0_RfR 0','0_RfR 1','0_RfR 2','1_RfR 0','1_RfR 1','1_RfR 2','2_RfR 0','2_RfR 1','2_RfR 2','3_RfR 0','3_RfR 1','3_RfR 2','4_RfR 0','4_RfR 1','4_RfR 2','EWS_DaysToThreat']\n",
    "\n",
    "cleaned_experiments = experiments.copy()\n",
    "cleaned_experiments.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:57:36.693811Z",
     "end_time": "2023-06-20T17:57:38.688986Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply PRIM\n",
    "x = cleaned_experiments\n",
    "y = (outcomes['Expected Number of Deaths'] <= 0.001) # the outcome constraint to evaluate using PRIM\n",
    "prim_alg = prim.Prim(x,y, threshold = 0.5, peel_alpha = 0.01)\n",
    "box = prim_alg.find_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:57:38.757220Z",
     "end_time": "2023-06-20T17:57:39.337935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot PRIM tradeoff graph\n",
    "box.show_tradeoff(annotated=True)\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    box.show_tradeoff(annotated=False)\n",
    "    plt.savefig(figures_path + f\"/prim_tradeoff.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO**: here we have to talk about the trade-offs between density and coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inspect PRIM results in graph style\n",
    "plot = box.inspect(style='graph')\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    plot.figure.savefig(figures_path + f\"/prim_inspect_graph.png\", dpi=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO-DO**: rewrite these PRIM conclusions a bit\n",
    "\n",
    "Bmax is not relevant for deaths. High pfail is correlated with higher deaths.\n",
    "This only cover 16% of the cases of interests with a density of 1. It is not very conclusive, PRIM had issues explaining the problem without restricting a significant number of dimensions (in the case of this image but once we run the final probably that changes)\n",
    "PRIM will always suffer a bit because the problem is not linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensional stacking\n",
    "\n",
    "As PRIM is not suited to this problem, we now use dimensional stacking to see if we can conclude something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:57:39.569818Z",
     "end_time": "2023-06-20T17:57:40.674343Z"
    }
   },
   "outputs": [],
   "source": [
    "dimensional_stacking.create_pivot_plot(cleaned_experiments, y)\n",
    "# Blank spaces mean that additional runs are needed for the coverage to increase and get conclusive results. However, as will be discussed, we find that this method is not suited to this problem, and thus we do not do that now.\n",
    "\n",
    "if save_figures:\n",
    "    plt.savefig(figures_path + f\"/dimensional_stacking_pivot.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will choose a point in the lower 25% (around 0.7 density and 0.7 coverage) to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-20T17:57:40.684809Z",
     "end_time": "2023-06-20T17:57:40.872481Z"
    }
   },
   "outputs": [],
   "source": [
    "point = 36\n",
    "box.inspect(point)\n",
    "plot = box.inspect(point, style='graph')\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    plot.figure.savefig.savefig(figures_path + f\"/dimensional_stacking_inspect_graph_{point}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this is not conclusive, except to say that pfail is importaint but not that one on dike ring 3. (**TO-DO**: rewrite sentence)\n",
    "We will resample another point in the upper 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    box.resample(point)\n",
    "except Exception as e:\n",
    "    print(\"Resample failed with exception: \" + e)\n",
    "    print(\"You can try to run this cell again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot to visually understand the PRIM process\n",
    "i = min(140,len(box.box_lims)) # limit to maximum\n",
    "\n",
    "box.select(i)\n",
    "box.show_pairs_scatter()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,12)\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    plt.savefig(figures_path + f\"/prim_box_scatter.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis using extra trees\n",
    "\n",
    "Extra trees is less computationally intensive than Sobol. We will use the feature score to understand which of the uncertain values have the highest effect on the outcomes of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the outcome expected number of deaths as prime indicator\n",
    "outcomes_deaths = outcomes['Expected Number of Deaths']\n",
    "outcomes_deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores\n",
    "scores = feature_scoring.get_ex_feature_scores(\n",
    "    cleaned_experiments,\n",
    "    outcomes_deaths,\n",
    "    max_features=0.6,\n",
    "    mode=scenario_discovery_util.RuleInductionType.REGRESSION\n",
    ")[0]\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "scores.T.plot(ax=ax)\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "ax.set_xlabel('Samples')\n",
    "ax.set_ylabel('Feature scores')\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    plt.savefig(figures_path + f\"/extratrees_scores.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness\n",
    "\n",
    "Two robustness metrics will be studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal-to-noise ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function defined as in assignment 9.\n",
    "def s_to_n(data, direction):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "\n",
    "    if direction==ScalarOutcome.MAXIMIZE:\n",
    "        return mean/std\n",
    "    else:\n",
    "        return mean*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_scores = {}\n",
    "\n",
    "# Loop over policies\n",
    "for policy in np.unique(experiments['policy']):\n",
    "    scores = {}\n",
    "\n",
    "    logical = experiments['policy'] == policy\n",
    "\n",
    "    for outcome in dike_model.outcomes:\n",
    "        value = outcomes[outcome.name][logical]\n",
    "        sn_ratio = s_to_n(value, outcome.kind)\n",
    "        scores[outcome.name] = sn_ratio\n",
    "    overall_scores[policy] = scores\n",
    "\n",
    "scores = pd.DataFrame.from_dict(overall_scores).T\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pool of scores\n",
    "score_data = scores\n",
    "score_limits = parcoords.get_limits(score_data)\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(score_limits)\n",
    "paraxes.plot(score_data)\n",
    "plt.title(\"Signal-to-noise ratio scores\")\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    paraxes.fig.savefig(figures_path + f\"/parcoords_sn.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code as in model answer for assignment 9\n",
    "def calculate_regret(data, best):\n",
    "    return np.abs(best-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_regret = {}\n",
    "max_regret = {}\n",
    "for outcome in dike_model.outcomes:\n",
    "    policy_column = experiments['policy']\n",
    "\n",
    "    # create a DataFrame with all the relevant information\n",
    "    # i.e., policy, scenario_id, and scores\n",
    "    data = pd.DataFrame({\n",
    "        outcome.name: outcomes[outcome.name],\n",
    "        \"policy\": experiments['policy'],\n",
    "        \"scenario\": experiments['scenario']\n",
    "    })\n",
    "\n",
    "    # reorient the data by indexing with policy and scenario id\n",
    "    data = data.pivot(index='scenario', columns='policy')\n",
    "\n",
    "    # flatten the resulting hierarchical index resulting from\n",
    "    # pivoting, (might be a nicer solution possible)\n",
    "    data.columns = data.columns.get_level_values(1)\n",
    "\n",
    "    outcome_regret = (data.max(axis=1).values[:, np.newaxis] - data).abs()\n",
    "\n",
    "    overall_regret[outcome.name] = outcome_regret\n",
    "    max_regret[outcome.name] = outcome_regret.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "max_regret_df = pd.DataFrame(max_regret)\n",
    "sns.heatmap(max_regret_df/max_regret_df.max(), cmap='viridis', annot=True)\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    plt.savefig(figures_path + f\"/maxregret_heatmap.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get unique color map values\n",
    "def get_cmap_color(cmap, value, max):\n",
    "    cmap = matplotlib.colormaps[cmap]\n",
    "    return cmap(value/max)\n",
    "\n",
    "# Plot parcoords\n",
    "data = max_regret\n",
    "limits = parcoords.get_limits(data)\n",
    "\n",
    "paraxes = parcoords.ParallelAxes(limits)\n",
    "for i, (index, row) in enumerate(data.iterrows()):\n",
    "    paraxes.plot(row.to_frame().T, label=str(index), color=get_cmap_color('viridis', i, data.shape[0] - 1))\n",
    "paraxes.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    paraxes.fig.savefig(figures_path + f\"/maxregret_parcoords.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_regret = collections.defaultdict(dict)\n",
    "for key, value in overall_regret.items():\n",
    "    for policy in value:\n",
    "        policy_regret[policy][key] = value[policy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates 2 plots with a shared y and x axis\n",
    "fig, axes = plt.subplots(\n",
    "    cols=2,\n",
    "    figsize=(10,5),\n",
    "    sharey=True,\n",
    "    sharex=True\n",
    ")\n",
    "\n",
    "# To ensure easy iteration over the axes grid, we turn it\n",
    "# into a list. Hard-coded because there are four plots.\n",
    "\n",
    "# Using zip to loop over axes and policy/regret together.\n",
    "for ax, (policy, regret) in zip(axes, policy_regret.items()):\n",
    "    data = pd.DataFrame(regret)\n",
    "\n",
    "    # We need to scale the regret to ensure fair visual\n",
    "    # comparison. We can do that by dividing by the maximum regret\n",
    "    data = data/max_regret.max(axis=0)\n",
    "    sns.boxplot(data=data, ax=ax)\n",
    "\n",
    "    # removes top and left hand black outline of axes\n",
    "    sns.despine()\n",
    "\n",
    "    # ensure we know which policy the figure is for\n",
    "    ax.set_title(str(policy))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if save_figures:\n",
    "    plt.savefig(figures_path + f\"/maxregret_policies.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
